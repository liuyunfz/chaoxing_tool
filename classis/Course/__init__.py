# _*_ coding:utf-8 _*_
# author: liuyunfz
import json
import re
import time
from urllib import parse
from loguru import logger
from lxml import etree

from utils import doGet, xpath_first, doPost


class Course:
    def __init__(self, course_id: str, class_id: str, url: str, course_name: str, course_author: str, cpi: str = "", headers: dict = {}, ifOpen: bool = True):
        self.course_id = course_id
        self.class_id = class_id
        self.url = url
        self.course_name = course_name
        self.course_author = course_author
        if cpi == "":
            self.cpi = parse.parse_qs(parse.urlparse(self.url).query).get("cpi")[0]
        self.chapter_list = []
        self.mission_all = 0
        self.mission_fn = 0
        self._child_chapter_list = []
        self.url_log = ""
        self.headers = headers
        self.ifOpen = ifOpen
        self._jobEnc = None

    def __str__(self) -> str:
        return "\n".join([f"CourseName: {self.course_name}",
                          f"Author: {self.course_author}",
                          f"Url: {self.url}",
                          f"CourseId: {self.course_id}",
                          f"ClazzId: {self.class_id}",
                          f"Cpi: {self.cpi}"])

    def get_chapter(self):
        self.chapter_list.clear()
        html_text = doGet(url=f"https://mooc2-ans.chaoxing.com/mooc2-ans/mycourse/studentcourse?courseid={self.course_id}&clazzid={self.class_id}&cpi={self.cpi}&ut=s&t={int(time.time())}", headers=self.headers)
        ele = etree.HTML(html_text)
        ele_root = xpath_first(ele, "//div[@class='fanyaChapterWhite']")
        self.mission_all = 0
        self.mission_fn = xpath_first(ele_root, "./div[1]/h2/span/text()")
        logger.info(f"mission_finished/mission_all: {self.mission_fn}/{self.mission_all}")
        ele_units = ele_root.xpath("./div[2]/div[@class='chapter_td']/div[@class='chapter_unit']")
        for unit in ele_units:
            unit_catalog_name = xpath_first(unit, "./div[1]/div[1]/div[@class='catalog_name']/span/text()").strip()
            """
            {
                1è®¡ç®—æœºç³»ç»Ÿæ¦‚è®º
                    1.1 è®¡ç®—æœºç³»ç»Ÿç®€ä»‹    1
                    1.1.1 è®¡ç®—æœºçš„è½¯ç¡¬ä»¶æ¦‚å¿µ    2
                    1.1.2 è®¡ç®—æœºç³»ç»Ÿçš„å±‚æ¬¡ç»“æž„    2
                    1.2 è®¡ç®—æœºçš„åŸºæœ¬ç»„æˆ    1
                    1.2.1 å†¯Â·è¯ºä¾æ›¼è®¡ç®—æœºçš„ç‰¹ç‚¹   2
                
            },{
                2è®¡ç®—æœºçš„å‘å±•åŠåº”ç”¨
                    2.1 è®¡ç®—æœºçš„å‘å±•å²    1
                    2.1.1 è®¡ç®—æœºçš„äº§ç”Ÿå’Œå‘å±•    2
                    2.1.2 å¾®åž‹è®¡ç®—æœºçš„å‡ºçŽ°å’Œå‘å±•    2
                    2.1.3 è½¯ä»¶æŠ€æœ¯çš„å…´èµ·å’Œå‘å±•    2
                    2.2 è®¡ç®—æœºçš„åº”ç”¨    1
            }
            """
            for item_li in unit.xpath("./div[2]/ul/li"):
                self.__recursion_chapter_item(item_li, 0)
            logger.debug(self._child_chapter_list)
            self.chapter_list.append({
                "catalog_name": unit_catalog_name,
                "child_chapter": self._child_chapter_list.copy()
            })
            self._child_chapter_list.clear()

    def __recursion_chapter_item(self, element, depth: int):
        if (click_data := xpath_first(element, "./div/@onclick")) != "":
            knowledge_id = click_data.split("'")[3]
        else:
            knowledge_id = ''
        self._child_chapter_list.append({
            "name": ("ðŸ”’ " if knowledge_id == '' else '') + xpath_first(element, "./div[1]/div[1]/div[@class='catalog_name']").xpath('string(.)').strip(),
            "depth": depth,
            "knowledge_id": knowledge_id,
            "job_count": int(xpath_first(element, "./div[1]/div[1]/div[@class='catalog_task']/input/@value") or "0"),
            "available": knowledge_id != ''
        })
        chapter_list = element.xpath("./ul/li")
        if chapter_list:
            for chapter_item in chapter_list:
                self.__recursion_chapter_item(chapter_item, depth + 1)

    def get_url_log(self) -> str:
        """
        èŽ·å¾—è¯¾ç¨‹è®°å½•å­¦ä¹ çš„é“¾æŽ¥ï¼ŒåŒæ—¶æ›´æ–°è¯¾ç¨‹çš„URL
        :return: è¯¾ç¨‹å­¦ä¹ è®°å½•çš„URL
        """
        if not self.url_log:
            self.url = f"https://mooc2-ans.chaoxing.com/mooc2-ans/mycourse/studentcourse?courseid={self.course_id}&clazzid={self.class_id}&cpi={self.cpi}&ut=s&t=1678608658539"
            _rsp = doGet(url=self.url, headers=self.headers)
            self.url_log = re.findall("(https://fystat-ans.chaoxing.com/log/setlog(.)+)\"></script>", _rsp)[0][0]
        return self.url_log

    def get_count_log(self) -> int:
        """

        :return: è¯¾ç¨‹å­¦ä¹ æ€»çš„æ¬¡æ•°
        """
        _headers = {
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
            'Connection': 'keep-alive',
            'Content-Length': '73',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'Host': 'stat2-ans.chaoxing.com'
        }
        _headers.update(self.headers)
        _rsp = doPost(url="https://stat2-ans.chaoxing.com/stat2/study-pv/chart", headers=_headers, data=f"clazzid={self.class_id}&courseid={self.course_id}&cpi={self.cpi}&ut=s&year=2023&month=03")
        return json.loads(_rsp).get("total")

    def get_time_log(self):
        """

        :param headers: è®¿é—®çš„è¯·æ±‚å¤´
        :return: è¯¾ç¨‹è§†é¢‘çš„ç´¯è®¡è§‚çœ‹æ—¶é—´ä¸Žæ€»æ—¶é•¿
        """
        _url = f"https://stat2-ans.chaoxing.com/stat2/task/s/index?courseid={self.course_id}&cpi={self.cpi}&clazzid={self.class_id}&ut=s&pEnc={self.jobEnc}&"
        _rsp = doGet(url=_url, headers=self.headers)
        _ele = etree.HTML(_rsp)
        _acc = xpath_first(_ele, "//div[@class='fl min']/span/text()")
        _all = re.findall(r'æ€»æ—¶é•¿ (\d+)', _rsp)[0]
        return [float(_acc), float(_all)]

    def get_progress_data(self):
        """

        :return:
        """

        _url_data = f"https://stat2-ans.chaoxing.com/stat2/task/s/progress/detail?clazzid={self.class_id}&courseid={self.course_id}&cpi={self.cpi}&ut=s&pEnc={self.jobEnc}&page=1&pageSize=16&status=0"
        _rsp = doGet(url=_url_data, headers=self.headers)
        return json.loads(_rsp).get("data").get("results")

    @property
    def jobEnc(self):
        if self._jobEnc is None:
            _url = f"https://stat2-ans.chaoxing.com/study-data/index?courseid={self.course_id}&clazzid={self.class_id}&cpi={self.cpi}&ut=s&t=1683984845824"
            _data = doGet(url=_url, headers=self.headers)
            self._jobEnc = re.findall(r"jobEnc = '(.*)';", _data)[0]
        return self._jobEnc
